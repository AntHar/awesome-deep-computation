
# Awesome Deep Computation [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
A curated list of awesome deep learning hardware, compute cycle/memory optimisation and implementation techniques.  Inspired by [awesome-deep-learning](https://github.com/ChristosChristofidis/awesome-deep-learning).
Only adding Literature published not prior to 2014.


#### Low Level Hardware

1.  2014/06 [A 240 G-ops/s Mobile Coprocessor for Deep Neural Networks](http://www.cv-foundation.org//openaccess/content_cvpr_workshops_2014/W17/papers/Gokhale_A_240_G-opss_2014_CVPR_paper.pdf)
2.  2015/02 [Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks](http://cadlab.cs.ucla.edu/~cong/slides/fpga2015_chen.pdf)
3.  2015/06 [Neuromorphic Architectures for Spiking Deep Neural Networks](http://ncs.ethz.ch/pubs/pdf/Indiveri_etal15.pdf)
4.  2015/06 [Memory and information processing in neuromorphic systems](http://arxiv.org/pdf/1506.03264.pdf)
5.  2015/08 [INsight: A Neuromorphic Computing System for Evaluation of Large Neural Networks](http://arxiv.org/pdf/1508.01008.pdf)
6.  2016/02 [Deep Learning on FPGAs: Past, Present, and Future.](http://arxiv.org/abs/1602.04283)
7.  2016/04 [Demonstrating Hybrid Learning in a Flexible Neuromorphic Hardware System](https://arxiv.org/pdf/1604.05080.pdf)
8.  2016/04 [Hardware-oriented Approximation of Convolutional Neural Networks](http://arxiv.org/pdf/1604.03168v2.pdf)

#### Model Techniques

1.  2014/12 [Training Deep Neural Neworks with Low Precision Multiplications](https://arxiv.org/pdf/1412.7024.pdf)
2.  2014/12 [Implementation of Deep Convolutional Neural Net on a Digital Signal Processor](http://cs229.stanford.edu/proj2014/Elaina%20Chai,Implementation%20of%20Deep%20Convolutional%20NeuralNet%20on%20a%20DSP.pdf)
3.  2015/02 [Deep Learning with Limited Numerical Precision](https://arxiv.org/pdf/1502.02551.pdf)
4.  2015/02 [Faster learning of deep stacked autoencoders on multi-core systems using synchronized layer-wise pre-training](https://arxiv.org/abs/1603.02836)
5.  2016/02 [Neural Networks with Few Multiplications](https://arxiv.org/abs/1510.03009)
6.  2016/02 [Deep Compression: Compressing Deep Neural Networks with Pruning, Quantization and Huffman Coding](http://arxiv.org/abs/1510.00149)
7.  2016/02 [8-Bit Approximations for Parallelism in Deep Learning](http://arxiv.org/abs/1511.04561)


#### Tutorials and talks

1.  2015/09 [Heterogeneous Computing in HPC and Deep Learning](https://hpcuserforum.com/presentations/colorado-sept2015/InspuHeterogeneousComputingInHPCandDeepLearning.pdf)
2.  2016/02 [Going Deeper with Embedded FPGA Platform for Convolutional Neural Network](http://www.isfpga.org/index_files/Slides/1_2.pdf)
3.  2016/02 [Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks](http://www.rle.mit.edu/eems/wp-content/uploads/2016/02/eyeriss_isscc_2016_slides.pdf)
4.  2016/05 [Deep Compression: Compressing Deep Neural Networks with Pruning, Quantization and Huffman Coding](http://videolectures.net/iclr2016_han_deep_compression/)

#### Thesis

1. 2015/08 [FPGA based Multi-core architectures for Deep Learning](https://etd.ohiolink.edu/!etd.send_file?accession=dayton1449417091&disposition=inline)

#### Whitepapers

1.  2015/02 [Accelerating Deep Convolutional Neural Networks Using Specialized Hardware](http://research.microsoft.com/pubs/240715/CNN%20Whitepaper.pdf)
2.  2015/07 [Efficient Implementation of Neural Network Systems Built on FPGAs, Programmed with OpenCL](https://www.altera.com/en_US/pdfs/literature/solution-sheets/efficient_neural_networks.pdf)

#### Blogs and Articles

1.  2015/05 [Numerical Optimization for Deep Learning](http://insidehpc.com/2015/05/numerical-optimization-for-deep-learning/)
2.  2015/10 [Single Node Caffe Scoring and Training on IntelÂ® Xeon E5-Series Processors](https://software.intel.com/en-us/articles/single-node-caffe-scoring-and-training-on-intel-xeon-e5-series-processors)
3.  2016/03 [FPGAs Challenge GPUs as a Platform for Deep Learning](https://www.tractica.com/automation-robotics/fpgas-challenge-gpus-as-a-platform-for-deep-learning/)
4.  2016/03 [FPGA with OpenCL Solution Released to Deep Learning](http://www.hpcwire.com/2016/03/17/fpga-opencl-solution-released-deep-learning/)
5.  2016/04 [Boosting Deep Learning with the Intel Scalable System Framework](http://www.nextplatform.com/2016/04/14/boosting-deep-learning-intel-scalable-system-framework/)
6.  2016/04 [Movidius puts deep learning chip in a USB drive](http://www.theverge.com/2016/4/28/11510430/movidius-fathom-neural-compute-stick-myriad-2-chip)
7.  2016/05 [The PCM-Neuron and Neural Computing](http://www.eetimes.com/author.asp?section_id=36&doc_id=1329754&)

#### Hardware platforms & accelerators

1.  [Nvidia Devbox](https://developer.nvidia.com/devbox)
2.  [Google Tensor Processing Unit](http://www.anandtech.com/show/10340/googles-tensor-processing-unit-what-we-know)
3.  [Facebook Open Rack V2 compatible 8-GPU server](https://code.facebook.com/posts/1687861518126048/facebook-to-open-source-ai-hardware-design/)
4.  [CEVA DNN Digital Signal Processor](http://www.ceva-dsp.com/CDNN)
5.  [Movidius Fathom USB Stick](http://uploads.movidius.com/1463004959-Fathom-Combined-2-pager-web.pdf)
6.  [IBM TrueNorth](http://www.research.ibm.com/articles/brain-chip.shtml)

#### Licenses
License

[![CC0](http://i.creativecommons.org/p/zero/1.0/88x31.png)](http://creativecommons.org/publicdomain/zero/1.0/)

